import numpy as np
from tensorflow import keras
from tensorflow.keras.datasets import imdb
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Embedding, Flatten

max_words = 10000
max_length = 250
embedding_size = 50

(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_words)

x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen= max_length)
x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen = max_length)

model = Sequential()
model.add(Embedding(max_words, embedding_size, input_length = max_length))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

batch_size = 32
epochs = 5
model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = (x_test, y_test))


loss, accuracy = model.evaluate(x_test, y_test)
print(f'Test loss: {loss:.4f}')
print(f'Test accuracy: {accuracy:.4f}')